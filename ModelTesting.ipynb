{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cab8c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import csv\n",
    "\n",
    "CSV_FILE = 'scrap_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9865de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open(CSV_FILE,'r') as csv_file:\n",
    "    csv_reader = csv.Reader(csv_file)\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        line_count+=1\n",
    "        if line_count == 1:\n",
    "            continue\n",
    "        if row[]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "14b709bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(CSV_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5e6998f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['text', 'font_size', 'font_color_red', 'font_color_green' , 'font_color_blue' , 'font_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e4f2092f-df97-4a5c-b6d9-46f8990d1143",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = dataset.drop(['font_color_alpha'], axis=1)\n",
    "# dset = dataset.drop('text', axis=1)\n",
    "le = preprocessing.LabelEncoder()\n",
    "dset['text'] = le.fit_transform(dset['text'])\n",
    "\n",
    "dset.drop_duplicates(inplace=True, keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6a63a5e7-3c90-4ead-98a2-a75d1eba221f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.31      0.39       157\n",
      "           1       0.81      0.92      0.86       498\n",
      "\n",
      "    accuracy                           0.77       655\n",
      "   macro avg       0.68      0.61      0.63       655\n",
      "weighted avg       0.75      0.77      0.75       655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dset2 = dset\n",
    "cpy = dset2\n",
    "\n",
    "dset2 = dset2.drop('output', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset2, cpy['output'], test_size=0.35, random_state=123)\n",
    "\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# SVM without sampling\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8bb812a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Down Sampling majority\n",
    "df_majority = dset[dset.output == 1]\n",
    "df_minority = dset[dset.output == 0]\n",
    "\n",
    "#df_majority_downsampled = resample(df_majority, replace=False,  n_samples=len(df_minority) , random_state=123) # reproducible results\n",
    "df_minority_downsampled = resample(df_minority, replace=True,  n_samples=int(len(df_majority)*0.6) , random_state=123) # reproducible results\n",
    "\n",
    "#dset = pd.concat([df_majority_downsampled, df_minority])\n",
    "dset = pd.concat([df_minority_downsampled, df_majority])\n",
    "\n",
    "cpy = dset\n",
    "dset = dset.drop('output', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dset, cpy['output'], test_size=0.35, random_state=123)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9ad123f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.45      0.53       303\n",
      "           1       0.72      0.85      0.78       502\n",
      "\n",
      "    accuracy                           0.70       805\n",
      "   macro avg       0.68      0.65      0.65       805\n",
      "weighted avg       0.69      0.70      0.68       805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With Upsampling Minority\n",
    "\n",
    "svm = SVC(kernel='poly')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "05e612b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7031055900621118\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "81bb500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73 (+/- 0.32)\n",
      "Accuracy: 0.7279503105590062\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "k = 5 # Set the number of folds\n",
    "scores = cross_val_score(dtc, dset, cpy[\"output\"], cv=k)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {scores.mean():.2f} (+/- {scores.std() * 2:.2f})\")\n",
    "\n",
    "# Without Cross Validation\n",
    "\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ba9024b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize an array to store the accuracy scores for each fold\n",
    "scores = []\n",
    "X = dset\n",
    "y = cpy['output']\n",
    "# Iterate over the k folds\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize the decision tree classifier\n",
    "    dtc = DecisionTreeClassifier(random_state=42)\n",
    "    \n",
    "    # Fit the classifier on the training data\n",
    "    dtc.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the target variable on the test data\n",
    "    y_pred = dtc.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy score for the fold and append it to the scores array\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "# Calculate the mean and standard deviation of the accuracy scores\n",
    "mean_score = sum(scores) / k\n",
    "std_dev = (sum((score - mean_score) ** 2 for score in scores) / k) ** 0.5\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {mean_score:.2f} (+/- {std_dev:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
